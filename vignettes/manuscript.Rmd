---
title: 'Modelling Lake Trophic State: A Random Forest Approach'
author:
- affilnum: 1
  email: hollister.jeff@epa.gov
  name: Jeffrey W. Hollister
- affilnum: 1
  name: W. Bryan Milstead
- affilnum: 1
  name: Betty J. Kreakie
affiliation:
- affil: US Environmental Protection Agency, Office of Research and Development, National Health
    and Environmental Effects Research Laboratory, Atlantic Ecology Division, 27 Tarzwell
    Drive  Narragansett, RI, 02882, USA
  affilnum: 1
output:
  pdf_document:
    fig_caption: yes
    keep_tex: yes
    number_sections: yes
    template: components/manuscript.latex
  word_document: 
    fig_caption: yes
    reference_docx: 
capsize: normalsize
csl: components/freshwater-science.csl
documentclass: article
fontsize: 11pt
linenumbers: yes
bibliography: components/LakeTrophicModelling.bib
running: Modelling Lake Trophic State
spacing: doublespacing
abstract: no
---

<!--
%\VignetteEngine{knitr::rmarkdown}
%\VignetteIndexEntry{Modelling Lake Trophic State: A Data Mining Approach}
-->

```{r setup, include=FALSE, echo=FALSE}
if(!require(LakeTrophicModelling)){
  devtools::install_github("USEPA/LakeTrophicModelling",quick=TRUE)
}
if(!require(wesanderson)){
devtools::install_github("jhollist/wesanderson")
}
if(!require(edarf)){
devtools::install_github("zmjones/edarf")
}
if(!require(condprob2)){
devtools::install_github("jhollist/condprob2")
}
#if(!require(caret)){
#  install.packages("caret")
#}
if(!require(tidyr)){
  install.packages("tidyr")
}
if(!require(party)){
  install.packages("party")
}

if(!require(broom)){
  install.packages("broom")
}

if(!require(doParallel)){
  install.packages("doParallel")
}
library("wesanderson")
library("LakeTrophicModelling")
library("knitr")
library("ggplot2")
library("sp")
library("rgdal")
library("e1071")
library("dplyr")
library("tidyr")
library("condprob2")
library("party")
library("broom")
library("edarf")
#library("caret")
library("randomForest")
library("doParallel")
opts_chunk$set(dev = 'jpeg', dpi=300, fig.width=7.5, knitr.table.format="html")
data(LakeTrophicModelling)

#
#Checks for existing cache (from another project)
#Else if Repeats running chunk outside of knitr
if(file.exists("prior_cache")){
  for(i in gsub(".rdb","",list.files("prior_cache",".rdb",full.names=T))){
    lazyLoad(i)
  }
} else if(file.exists("vignettes/prior_cache")){
  for(i in gsub(".rdb","",list.files("vignettes/prior_cache",".rdb",full.names=T))){
    lazyLoad(i)
  }
} else if(file.exists("../prior_cache")){
  for(i in gsub(".rdb","",list.files("../prior_cache",".rdb",full.names=T))){
    lazyLoad(i)
  }
}

# Table Captions from @DeanK on 
#http://stackoverflow.com/questions/15258233/using-table-caption-on-r-markdown-file-using-knitr-to-use-in-pandoc-to-convert-t

knit_hooks$set(tab.cap = function(before, options, envir) {
                  if(!before) { 
                    paste('\n\n:', options$tab.cap, sep='') 
                  }
                })
default_output_hook = knit_hooks$get("output")
knit_hooks$set(output = function(x, options) {
  if (is.null(options$tab.cap) == FALSE) {
    x
  } else
    default_output_hook(x,options)
})
```

```{r data_setup ,echo=FALSE}
#All Variables
#Clean Up Data - Complete Cases
predictors_all <- predictors_all[predictors_all!="DATE_COL"]
all_dat <- data.frame(ltmData[predictors_all],LogCHLA=log10(ltmData$CHLA))
row.names(all_dat)<-ltmData$NLA_ID
all_dat <- all_dat[complete.cases(all_dat),]  

#GIS Variables
#Clean Up Data - Complete Cases
gis_dat <- data.frame(ltmData[predictors_gis],LogCHLA=log10(ltmData$CHLA))
row.names(gis_dat)<-ltmData$NLA_ID
gis_dat <- gis_dat[complete.cases(gis_dat),]
```

```{r rand_forest_runs , eval=FALSE, include=FALSE, echo=FALSE, cache=FALSE}
################################################################################
#This chunk sets up the 'all' and 'gis' data, does variable selection (takes few
# hours to run) then run the randomForest.
# Results stored in prior_cache and loaded in setup chunk
################################################################################
#Model 1: All Variables

#Variable Selection
all_vs <- varsel_regression_rf(all_dat$LogCHLA,all_dat[,names(all_dat)!="LogCHLA"],
                     ntree=5000,prog=T)  
all_vs_plot <- varsel_plot(all_vs) #Used plot to identify approxiamte minimum
all_vars_select <- unlist(all_vs$vars[19]) #top 20 variables

#Final Model - all variables
all_rf<-randomForest(y=all_dat$LogCHLA,x=all_dat[,all_vars_select], 
                         ntree=5000,importance=TRUE,proximity=TRUE,
                          keep.forest=TRUE,keep.inbag=TRUE)
  
################################################################################
#Model 2: GIS Only Variables

#Variable Selection
gis_vs <- varsel_regression_rf(gis_dat$LogCHLA,gis_dat[,names(gis_dat)!="LogCHLA"],
                     ntree=5000,prog=T)  
gis_vs_plot <- varsel_plot(gis_vs) #Used plot to identify approxiamte minimum
gis_vars_select <- unlist(gis_vs$vars[14]) #top 15 variables

#Final Model - gis variables
gis_rf<-randomForest(y=gis_dat$LogCHLA,x=gis_dat[,gis_vars_select], 
                       ntree=5000,importance=TRUE,proximity=TRUE,
                        keep.forest=TRUE,keep.inbag=TRUE)

```

```{r rf_var_importance, eval=TRUE, echo=FALSE, cache=TRUE, warning=FALSE}

all_imp <- importance(all_rf)
gis_imp <- importance(gis_rf)
var_importance<-rbind(varImportance(all_imp,"All variables"),
                      varImportance(gis_imp,"GIS variables"))
var_importance<-inner_join(var_importance,data_def[c("variable_names","description")],"variable_names")
var_importance<-var_importance[order(var_importance$model_id,-var_importance$mean_decrease_gini, decreasing=FALSE),]                     
```


```{r rf_pd, eval=TRUE, echo=FALSE, cache=TRUE, warning=FALSE}
################################################################################
#Register parallel backend for partial dependence
numcores<-parallel::detectCores()
cl <- makeCluster(numcores)
registerDoParallel(cl)
co <- 25L

################################################################################
#All variables partial dependence
all_rf_turb_pd<-partial_dependence(all_rf,all_dat,"TURB",cutoff = co, ci=FALSE,
                                   parallel = TRUE)
all_rf_ntl_pd<-partial_dependence(all_rf,all_dat,"NTL",cutoff = co,ci=FALSE,
                   parallel = TRUE)
all_rf_ptl_pd<-partial_dependence(all_rf,all_dat,"PTL",cutoff = co,ci=FALSE,
                   parallel = TRUE)
all_rf_elev_pd<-partial_dependence(all_rf,all_dat,"ELEV_PT",cutoff = co,ci=FALSE,
                   parallel = TRUE)
all_rf_toc_pd<-partial_dependence(all_rf,all_dat,"TOC",cutoff = co,ci=FALSE,
                   parallel = TRUE)
all_rf_np_pd<-partial_dependence(all_rf,all_dat,"NPratio",cutoff = co,ci=FALSE,
                   parallel = TRUE)

################################################################################
#GIS Only partial dependence
gis_rf_ecor_pd<-partial_dependence(gis_rf,gis_dat,"WSA_ECO9",cutoff = co, ci=FALSE,
                                   parallel = TRUE)
gis_rf_crops_pd<-partial_dependence(gis_rf,gis_dat,"CropsPer_3000m",cutoff = co, 
                                    ci=FALSE, parallel = TRUE)
gis_rf_elev_pd<-partial_dependence(gis_rf,gis_dat,"ELEV_PT",cutoff = co, ci=FALSE,
                   parallel = TRUE)
gis_rf_lat_pd<-partial_dependence(gis_rf,gis_dat,"AlbersY",cutoff = co, ci=FALSE,
                   parallel = TRUE)
gis_rf_conifer_pd<-partial_dependence(gis_rf,gis_dat,"EvergreenPer_3000m",cutoff = co, 
                                      ci=FALSE, parallel = TRUE)
gis_rf_mndepth_pd<-partial_dependence(gis_rf,gis_dat,"MeanDepthCorrect",cutoff = co, 
                                      ci=FALSE, parallel = TRUE)

stopCluster(cl)
```

```{r trophic_class, eval=TRUE, echo=FALSE, cache=TRUE, warning=FALSE}
#Predict and Original Chl a
all_pred <- predict(all_rf)
all_orig <- all_rf$y
gis_pred <- predict(gis_rf)
gis_orig <- gis_rf$y

#Trophic State Catergories
ts_4_brks <- c(min(log10(ltmData$CHLA),na.rm=T)-1,log10(2),log10(7),log10(30),max(log10(ltmData$CHLA),na.rm=T)+1)
ts_4_cats <- c("oligo","meso","eu","hyper")
ts_2_brks <- c(min(log10(ltmData$CHLA),na.rm=T)-1,log10(7),max(log10(ltmData$CHLA),na.rm=T)+1)
ts_2_cats <- c("oligo/meso","eu/hyper")

#Orig and Predict Trophic State Categories
all_ts4_pred <- cut(all_pred,ts_4_brks,ts_4_cats)
all_ts4_orig <- cut(all_orig,ts_4_brks,ts_4_cats)
all_ts2_pred <- cut(all_pred,ts_2_brks,ts_2_cats)
all_ts2_orig <- cut(all_orig,ts_2_brks,ts_2_cats)
gis_ts4_pred <- cut(gis_pred,ts_4_brks,ts_4_cats)
gis_ts4_orig <- cut(gis_orig,ts_4_brks,ts_4_cats)
gis_ts2_pred <- cut(gis_pred,ts_2_brks,ts_2_cats)
gis_ts2_orig <- cut(gis_orig,ts_2_brks,ts_2_cats)

#Trophic State Confusion Matrices
all_ts4_conmat <- table(all_ts4_pred,all_ts4_orig)
all_ts2_conmat <- table(all_ts2_pred,all_ts2_orig)
gis_ts4_conmat <- table(gis_ts4_pred,gis_ts4_orig)
gis_ts2_conmat <- table(gis_ts2_pred,gis_ts2_orig)

#Trophic State Total Accuracy and Kappa
all_ts4_total_acc <- classAgreement(all_ts4_conmat)$diag
all_ts4_kappa <- classAgreement(all_ts4_conmat)$kappa
all_ts2_total_acc <- classAgreement(all_ts2_conmat)$diag
all_ts2_kappa <- classAgreement(all_ts2_conmat)$kappa
gis_ts4_total_acc <- classAgreement(gis_ts4_conmat)$diag
gis_ts4_kappa <- classAgreement(gis_ts4_conmat)$kappa
gis_ts2_total_acc <- classAgreement(gis_ts2_conmat)$diag
gis_ts2_kappa <- classAgreement(gis_ts2_conmat)$kappa
```

```{r class_predict_probability, eval=TRUE, echo=FALSE, cache=TRUE, warning=FALSE}
#Per tree chl a predictions - All Variables
all_rf_ts_prob <- class_prob_rf(all_rf,all_dat,ts_4_brks,ts_4_cats,T)
gis_rf_ts_prob <- class_prob_rf(gis_rf,gis_dat,ts_4_brks,ts_4_cats,T)

```


\singlespace

\vspace{2mm}\hrule


**Abstract**  
Productivity of lentic ecosystems is well studied and it is widely accepted that as nutrient inputs increase,  productivity increases and lakes transition from lower trophic state (e.g. oligotrophic) to higher trophic states  (e.g. eutrophic). These broad trophic state classifications are good predictors of ecosystem condition, services, and disservices (e.g. recreation, aesthetics, and harmful algal blooms). While the relationship between  nutrients and trophic state provides reliable predictions, it requires *in situ* water quality data in order to parameterize the model.  This limits the application of these models to lakes with existing and, more importantly, available water quality data.  To address this, we take advantage of the availability of a large national lakes water quality database (i.e. the National Lakes Assessment), land use/land cover data, lake morphometry data, other universally available data, and apply data mining approaches to predict trophic state.   Using this data and random forests, we first model chlorophyll *a*, then classify the resultant predictions into trophic states.  The full model estimates chlorophyll *a* with both *in situ* and universally available data.  The mean squared error and adjusted R\textsuperscript{2} of this model was `r round(all_rf$mse[all_rf$ntree],2)` and `r round(all_rf$rsq[all_rf$ntree],2)`, respectively.  The second model uses universally available GIS data only. The mean squared error was `r round(gis_rf$mse[gis_rf$ntree],2)` and the adjusted R\textsuperscript{2} was `r round(gis_rf$rsq[gis_rf$ntree],2)`.  The accuracy of the trophic state classifications derived from the chlorophyll *a* predictions were `r round(all_ts4_total_acc,2)*100`% for the full model and `r round(gis_ts4_total_acc,2)*100`% for the "GIS only" model.  Random forests extend the usefulness of the class predictions by providing prediction probabilities for each lake.  This allows us to make trophic state predictions and also indicate the level of uncertainity around those predictions.  For the full model, these predicted class probabilites ranged from `r round(min(all_rf_ts_prob$max),2)` to `r round(max(all_rf_ts_prob$max),2)`.  For the GIS only model, they ranged from `r round(min(gis_rf_ts_prob$max),2)` to `r round(max(gis_rf_ts_prob$max),2)`.  It is our conclusion that *in situ* data are required for better predictions, yet GIS and universally available data provide trophic state predictions, with estimated uncertainty, that still have the potential for a broad array of applications.  The source code and data for this manuscript are available from https://github.com/USEPA/LakeTrophicModelling.


\vspace{3mm}\hrule
\doublespace


#Introduction
Productivity in lentic systems is often categorized across a range of trophic states (e.g. the trophic continuum) from early successional (i.e. oligotrophic) to late successional lakes (i.e. hypereutrophic) with lakes naturally occurring across this range [@carlson1977trophic]. Oligotrophic lakes occur in nutrient poor areas or have a more recent geologic history, are often found in higher elevations, have clear water, and are usually favored for drinking water or direct contact recreation (e.g. swimming).   Lakes with higher productivity (e.g. mesotrophic and eutrophic lakes) have greater nutrient loads, tend to be less clear, have greater density of aquatic plants, and often support more diverse and abundant fish communities. Higher primary productivity is not necessarily a predictor of poor ecological condition as it is natural for lakes to shift from lower to higher trophic states but this is a slow process [@rodhe1969crystallization]. However, at the highest productivity levels (hypereutrophic lakes) biological integrity is compromised [@hasler1969cultural; @schindler2008algal; @smith1999eutrophication].  

Monitoring trophic state allows for rapid assessment of a lakes biological productivity and identification of lakes with unusually high productivity (e.g. hypereutrophic).  These cases are indicative of lakes under greater anthropogenic nutrient loads, also known as cultural eutrophication, and are more likely to be at risk of fish kills, beach fouling, and harmful algal blooms [@smith1998cultural;@smith1999eutrophication;@smith2006eutrophication].  Given the association between trophic state and many ecosystem services and disservices, being able to accurately model trophic state could provide a first cut at identifying lakes with the potential for harmful algal blooms (i.e. from cyanobacteria) or other problems associated with cultural eutrophication.  This type of information could be used for setting priorities for managment and allow for more efficient use of limited resources.

As trophic state and related indices can be best defined by a number of *in situ* water quality parameters (modeled or measured), most models have used this information as predictors [@carvalho_cyanobacterial_2011;@milstead2013estimating;@imboden1978dynamic;@salas1991simplified].  This leads to accurate models, but also requires data that are often sparse and not always available, thus limiting the population of lakes for which we can make predictions.  A possible solution for this issue is to build models that use widely available data that are correlated to many of the *in situ* variables. For instance, landscape metrics of forests, agriculture, wetlands, and urban land in contributing watersheds have all been shown to explain a significant proportion of the variation (ranging from 50-86%, depending on study) in nutrients in receiving waters [@jones2001predicting; @jones2004importance; @seilheimer2013landscape].  Building on these previously identified associations might allow us to use only landscape and other universally available data to build models.  Identifying predictors using this type of ubiquitous data would allow for estimating trophic state in both monitored and unmonitored lakes. 

Many published models of nutrients and trophic state in freshwater systems are based on linear modelling methods such as standard least squares regression or linear mixed models [@jones2004importance; @jones2001predicting].  While these methods have proven to be reliable, they have limitations (e.g. independence, distribution assumptions, and outlier sensitivity).  Using data mining approaches, such as random forests, avoids many of the limitations, may reduce bias and often provides better predictions [@cutler2007random; @peters2007random; @breiman2001random; @delgado2014].  For instance, random forests are non-parametric and thus the data do not need to come from a specific distribution (e.g. Gaussian) and can contain collinear variables [@cutler2007random]. Second, random forests work well with very large numbers of predictors [@cutler2007random].  Lastly, random forests can deal with model selection uncertainty as predictions are based upon a consensus of many models and not just a single model selected with some measure of goodness of fit. 

To build on past work, we have identified three areas in which this research contributes.  First, we build, assess, and compare two random forest models of chlorophyll *a* 1) *in situ* and universally available GIS data and then 2) universally available GIS data only. Second, we convert the chlorophyll *a* estimates, for both models, to trophic state and assess the prediction accuracy and uncertainty.  Third, we examine the important predictors for both models. Lastly, this paper, the code, and the data used in the models are made available as an R package from https://github.com/USEPA/LakeTrophicModelling.  

#Methods

##Data and Study Area
We utilized three primary sources of data for this study, the National Lakes Assessment (NLA), the National Land Cover Dataset (NLCD), and  lake morphometery modeled from the NHDPlus and National Elevation Data Set [@usepa2009national;@homer2004development;@xian2009updating;@hollister2010volume;@hollister_predicting_2011;@lakemorpho2014].  All datasets are national in extent and provide a unique snapshot view of the condition of lakes in the conterminous United States during the summer of 2007.

The NLA data were collected during the summer of 2007 and the final data were released in 2009 [@usepa2009national for detailed description of methods].  With consistent methods and metrics collected at over 1000 locations across the conterminous United States (Figure \ref{fig:nlaMap}), the NLA provides a unique opportunity to examine broad scale patterns in lake productivity.  The NLA collected data on biophysical measures of lake water quality and habitat as well as an assessment of the phytoplankton community.  For this analysis, we only use the various water quality measurements from the National Lakes Assessment [@usepa2009national].   

Adding to the monitoring data collected via the NLA, we use the 2006 NLCD data to examine landscape-level drivers of trophic status in lakes.  The NLCD is a national land use/land cover dataset that also provides estimates of impervious surface.  We calculated total proportion of each NLCD land use land cover class and total percent impervious surface within a 3 kilometer buffer surrounding each lake [@homer2004development;@xian2009updating].  A three kilometer buffer was selected as an intermediate measure of the adjacent neighborhood; the three kilometer buffer size is greater than the immediate parcel but smaller than regional  and whole-basin measures.  

To account for unique aspects of each lake and to characterize lake productivity, we used measures of lake morphometry (i.e. depth, volume, fetch, etc.).  As these data are difficult to obtain for large numbers of lakes over broad regions, we used modeled estimates of lake morphometry [@hollister2010volume;@hollister_predicting_2011;@lakemorpho2014]. These included: surface area, shoreline length, Shoreline Development, Maximum Depth, Mean Depth, Lake Volume, Maximum Lake Length, Mean Lake Width, Maximum Lake Width, and Fetch.  

##Predicting Trophic State with Random Forests
Random forest is a machine learning algorithm that aggregates numerous decision trees in order to obtain a consensus prediction of the response categories [@breiman2001random].  Bootstrapped sample data are recursively partitioned according to a given random subset of predictor variables and a predetermined number of decision trees  are developed.   With each new tree, the sample data subset is randomly selected and with each new split, the subset of predictor variables are randomly selected.  A detailed discussion of the benefits of a random forest approach is beyond the scope of this paper.  To find out more see Breiman [-@breiman2001random] and Cutler et al. [-@cutler2007random].

Random forests are able to handle numerous correlated variables without a decrease in prediction accuracy; however, one possible shortcoming of this approach is that the resulting model may be difficult to interpret, thus selecting the most important variables is an important first step.  Several methods have been proposed to do this with random forest.  For instance, this is a problem often faced in gene selection and in that field, a variable selection method based on random forest has been successfully applied and implemented in the R Language as the `varSelRF` package [@diaz2006gene], but this is limited to classification problems.  Additionally, others have suggested alternative variable importance measures, but this is only needed with a large number of categorical variables which are selected against with traditional random forest approach [@strobl2007bias].  

In our case, we are predicting a continuous variable, chlorophyll *a*, directly thus `varSelRF`, does not apply, and all of our variables are continuous so the approach suggested by Strobl [-@strobl2007bias] is not necessary.  Thus we developed an approach, similar to `varSelRF` but applied to random forest with regression trees.  With this approach we fit a full random forest model that includes all variables and a large number of trees.  We then rank the variables using the increase in mean square error, which has been shown to be a less biased metric of importance than the mean decrease in the gini coeffecient [@strobl2007bias].  Using this ranking, we then iterate through the variables and create a random forest with the top two variables and record mean square error and adjusted R\textsuperscript{2} of the resultant random forest. We then repeat this process by adding the next most important variable in order of importance.  With this information we identify both the top variables and the point at which adding variables does not improve the fit of the overall model.  These variables are selected and used as the "reduced model."  With this method, a minimum set of variables that maximizes model accuracy is provided.  This allows us to start with a full suite of predictor variables from which to select a minimum, easier to interpret set of variables.  

<!---it is unclear to me how you are predictiong the "continuous variable".  Are you using the random forest similar to the CART process with the tree leading to a regression equation? If so, what are the predictor variables for the regression equations?  TN & TP? This is the section that needs more information. --->

<!-- jwh response: The regression trees are built with all the predictors and for each split the variables use are randomly selected.  Not feasible to list all possible regression equations... -->

##Model Details
Using `randomForest` R package we ran models to predict chlorphyll *a* with two sets of predictors [@liaw2002randomForest].  The first included *in situ* and universally available GIS predictors.  We refer to this as the "All variables" model.  Second, we use just the univerally available data (i.e. no *in situ* information).  This is referred to as the "GIS only" model. A list of the full suite of variables tested is in Appendix 1. Our separation of predictors was chosen so that we could highlight the additional predictive performance provided by adding the *in situ* water quality variables on top of the GIS only variables.  Lastly, we used only complete cases (i.e. missing data were removed) so the total number of observations varied among models. 

Our modelling work flow was as follows:

1. Identify a minimal set of variables that maximize accuracy of the random forest algorithm. This minimal set of variables, the reduced model, is calculated for each of the models. 
2. Using R's `randomForest` package, we develop two random forest models ("All variables" and "GIS only").
3. Assess model performance for both the predicted chlorophyll *a* and for categorical trophic state classifications.  Trophic state was defined using the NLA chlorophyll *a* trophic state cut offs (Table \ref{tab:trophicStateTable}). 
4. Examine importance and partial dependence of the most important variables.

##Measures of Model Performance and Variable Importance

We assessed the performance of the random forest two ways.  First we compare the root mean square error and the adjusted R\textsuperscript{2} of the models.  Second, we examine the accuracy of the model predictions when converted to trophic states classes (Table \ref{tab:trophicStateTable}).   We assess the classifcations via a confusion matrix. A confusion matrix shows agreement and disagreement in a tabular form with predicted values forming the columns of the matrix and observed values, the rows.  From this tabulated information we calculate the total accuracy (i.e. percent correctly predicted) and the kappa coefficient, which takes into account the error expected by chance alone (i.e. the off diagonal values of the matrix) [@cohen1960coefficient; @hubert1985comparing].   The kappa coefficient can range from -1 to 1 with 0 equalling the agreement expected by chance alone.  Values greater than 0 represent agreement greater than would be expected by chance, with values greater than 0.61 considered "substantial" agreement  [@landis1977measurement].  Negative values are rare and would indicate no agreement between the predicted and observed values. Additonally, random forest builds each tree on bootstrapped, random subsets of the original data, thus, a separate independent validation dataset is not required and random forest error estimates are expected to be unbiased [@breiman2001random]. 

<!---are they data bootstrapped? I thought that a random subset of the data were generated (as mentioned above) for each tree (i.e., sampled without replacement)--->
<!--They are bootsrapped.  That results in ~2/3 traing and ~1/3 test-->

The random forest algorithm explicitly measures variable importance with two metrics: mean decrease in Gini and percent increase in mean squared error.  For each of these they measure the impact on the overall model when that particular variable is included and thus can be used to assess importance [@breiman2001random]. The Gini Index has been shown to have a bias [@strobl2007bias], thus, we use percent increase in mean squared error to assess variable importance.  Lastly, partial dependence plots provide a mecahnism to examine the partial relationship between individual variables and the response variable [@jones2015exploratory]. We examine these plots for the top variables as assigned by percent increase in mean squared error for each the reduced models. 

##Trophic State Probabilities
One of the powerful features of random forests is the ability to aggregate a very large number of competing models or trees.  Each tree provides an independent prediction or vote for a possible outcome.  In the context of our chlorophyll *a* models, we have 5,000 estimates of chlorophyll *a* for each lake.  We convert these values to trophic states (Table \ref {tab:trophicStateTable}) then count up total votes for each class and divide by total possible votes to get an estimate of the probability that a lake is in a given trophic state. For instance, for a single lake (National Lake Assessment ID = NLA06608-0005), the vote probabilities for the "All variables" model were `r 100*round(all_rf_ts_prob[all_rf_ts_prob$nla_id=="NLA06608-0005",][1],2)`% for oligotrophic, `r 100*round(all_rf_ts_prob[all_rf_ts_prob$nla_id=="NLA06608-0005",][2],2)`% for mesotrophic, `r 100*round(all_rf_ts_prob[all_rf_ts_prob$nla_id=="NLA06608-0005",][3],2)`% for eutrophic, and `r 100*round(all_rf_ts_prob[all_rf_ts_prob$nla_id=="NLA06608-0005",][4],2)`% for hypereutrophic.  The maximum probability provides the predicted class, in this case oligotrphic, and suggests little uncertainty in this prediction.  We refer to this value as the "prediction probability."

Further, we might expect higher total accuracy for lakes that have more certain predictions.  This should be evident by looking at the total classification accuracy of lakes given their prediction probability is at or above a certain probability.  To test this we use an approach similar to one outlined by Paul and MacDonald [-@paul2005development] and implemented by Hollister et al. [-@hollister2008cprob].  We utilize this approach and examine the change in total accuracy as a function of the prediction probability for both models.  

#Results 
Our complete dataset included `r nrow(ltmData)` lakes; however `r sum(is.na(ltmData$CHLA))` lakes did not have chlorophyll *a* data. Thus, the base dataset for our modelling was conducted on data for `r nrow(ltmData[!is.na(ltmData$TS_CHLA_4),])` lakes.  The lakes were well distributed both across the four trophic state categories (Table \ref{tab:trophicStateTable}) and spatially throughout the United States (Figure \ref{fig:nlaMap}).  

##Models: All Variables
The model built with all predictors used `r nrow(all_dat)` total observations, had a mean squared error of `r round(all_rf$mse[5000],2)` and and R\textsuperscript{2} of `r round(all_rf$rsq[5000],2)`.  The accuracy of the four trophic states was `r round(all_ts4_total_acc,3)*100`% and the kappa coefficient was `r round(all_ts4_kappa,2)` (Table \ref{tab:Confusion_All_4}).  The variable selection process identified 20 variables (Figure \ref{fig:all_varsel_figure}).  The six most important variables were turbidity, total phosphorus, total nitrogen, elevation, total organic carbon, and N:P ratio (Figures \ref{fig:All_Importance}).  The role that each played in predicting chlorophyll *a* varied (Figure \ref{fig:all_partial_dependence}). 

##Models: GIS Only Variables
The GIS only model was built using `r nrow(gis_dat)` total observations, had a mean squared error of `r round(gis_rf$mse[5000],2)` and and R\textsuperscript{2} `r round(gis_rf$rsq[5000],2)`. Four trophic states were predicted with a total accuracy of `r round(gis_ts4_total_acc,3)*100`% and had a kappa coefficient of `r round(gis_ts4_kappa,2)` (Table \ref{tab:Confusion_GIS_4}).  The variable selection process for this model produced a reduced model with 15 variables (Figure \ref{fig:gis_varsel_figure}).  The six most important variables were ecoregion, percent cropland, elevation, latitude, percent evegreen forest, and mean lake depth (Figures \ref{fig:GIS_Importance} & \ref{fig:all_partial_dependence}).  

##Trophic State Probabilities
The "All variables" model provides more certain model predictions with a median prediction probability of `r round(median(apply(all_rf_ts_prob[1:4],1,max)),2)` versus `r round(median(apply(gis_rf_ts_prob[1:4],1,max)),2)` for the "GIS only" model (Figure \ref{fig:prob_cdf}).  Additionally, total accuracy of the predictions is a function of this uncertainty.  Lakes with more certain predictions were more accurately classified (Figure \ref{fig:cond_prob_fig}).  For both models, when prediction probabilites are approximately 0.8 or higher, the models had an accuracy of ~100%.  This represents `r round(sum(all_rf_ts_prob$max>0.8)/nrow(all_dat),2)*100`% of the lakes for the "All variables" model and `r round(sum(gis_rf_ts_prob$max>0.8)/nrow(gis_dat),2)*100`% of the lakes for the "GIS only" model.  Lastly, as prediction probabilites increased, the difference in total accuracy between the two models decreased (Figure \ref{fig:cond_prob_fig} & Table \ref{tab:cond_prob_tab}). 

#Discussion

##Trophic State Probabilities
Not surprisingly, lakes with more certain predictions (i.e. higher prediction probabilities) were more accurately predicted (Figure \ref{fig:cond_prob_fig}).  The fact that the difference in accuracy between the two models decreased as certainty in the prediction increased suggests that models with lower overall accuracy, such as the "GIS only" model, may have acceptable accuracy for many individual cases (Table \ref{tab:cond_prob_tab}).  Additionally, the prediction probabilities may be mapped for each of the four classes (Figure \ref{fig:gis_probability_map}).  

A map of this sort indicates several things.  First, since low uncertainty is associated with high accuracy this map shows the broad spatial patterns of lake trophic state across the United States.  The spatial patterns show little variability between the "All variables" and "GIS only" models, thus we only show the reuslts from the more broadly applicable "GIS only" model (Figure \ref{fig:gis_probability_map}).  Hypereutrophic lakes are much more commonly predicted in the midwest and southeastern United States.  Clear, oligotrophic lakes are in the northwestern United States, through the western mountains and in the northeastern united states.  The middle trophic states are more evenly distributed across the country.  Secondly, instead of mapping the probabilities for each trophic state separately, we can also map the prediction probabilities of the discrete predicted class. (Figure \ref{fig:predicted_prob_map}).  This map shows where the model predicts well and where it is less certain. In general, the map shows most points with higher prediction probabilities than the midpoint of the range and the distribution of prediction probabilities is skewed left (Figure \ref{fig:pred_prob_dist}).  While these patterns are not strong, they suggest that with slight improvements in the "GIS only" model we could skew the prediction probabilites futher left and easily improve the overall accuracy of the model.  This could be done using modeled, national estimates of nutrient loads [e.g. @milstead2013estimating; @moore_source_2011].

## Partial dependencies of explanatory variables
In line with past predictive modelling of chlorophyll *a* concentrations the "All variables" model selected the water quality variables (turbidity, total organic carbon, total nitrogen, total phosphorus, and N:P ratios) as important variables [@downing2001predicting].   While there is variation in the response of chlorophyll *a* to changes in nutrient concentrations, the general pattern suggests that limiting nutrients have a predictable impacts.  If we examine the partial dependencies of these variables we see a general linear increase in log chlorophyll *a* with nitrogen, phosphorus and organic carbon concentrations (Figure \ref{fig:all_partial_dependence}).  This relationship holds until nutrient concentrations become saturated.  The partial dependency plots (Figure \ref{fig:all_partial_dependence}) for the nitrogen:phosphorus ratio is more complicated, indicating that for ratios less than ~14 chlorophyll *a* increases but after ~14 there is marked decrease. The effect of the nitrogen phosphorus ratio on chlorophyll has been the subject of considerable research and our results are consistent with the majority of the findings suggesting that at low ratio values nitrogen is limiting [@downing1992nitrogen; @smith2009eutrophication].  Conversely at higher ratios the phosphorus levels may be limiting. This would be a cause for concern with linear models; however, linearity is not an assumption of tree-based modelling approaches such as random forest. 

Turbidity was selected as the most important variable in the "All variables" model.  The partial dependency analysis shows that, similar to the nutrients discussed above, log chlorophyll *a* increases with increased turbidity.  At first this may seem counter intuitive since we might expect productivity to decrease as turbidity increases, and therefore light availability decreases [@tilzer1988secchi; @bilotta2008understanding].  However, algal biomass can contribute heavily to measures of turbidity and we expect greater productivity to lead to increased turbidity [@hansson1992factors].  We interpret this pattern as indicating that as chlorophyll *a* concentrations increase we see a concomitant increase in turbidity.

Elevation was selected as an important predictive variable in both the all variables and the GIS only models; the partial dependencies (Figures \ref{fig:all_partial_dependence} & \ref{fig:gis_partial_dependence}) indicate a negative relationship between elevation and chlorophyll *a* concentration that is probably due to fact that the location of mountains in the United States is the spatial inverse of the distribution of agricultural and urban lands.  As elevation increases we expect decreased loads due to smaller watershed contributing areas. In contrast lower elevation sites will have larger drainage areas and greater potential for increased nutrient loads from urban and agricultural sources.  

The variables in the "GIS only" model captured the large scale spatial pattern of the trophic status gradient of lakes across the United States.  In addition to elevation, mentioned above, the model was most sensitive to latitude and ecoregion.  In general, chlorophyll *a* concentrations are highest in the Southern portions of the study area where temperatures can be higher (a known driver of productivity), elevations lower, and agricultural impacts more pronounced.   Likewise ecoregion (see Figure \ref{fig:}) has a pronounced affect indicting continental scale effects of land use and geography.  Agriculturally dominated landscapes such as the Temperate Plains, Southern Plains, and Coastal Plains show the highest levels of Chlorophyll *a*.  Whereas high elevation zones (Western Mountains), arid lands (Xeric), Northern habitats (Upper Midwest) have lower concentrations.

Further evidence for the role of land use/land cover variables is shown by the selection of the percent cropland and percent evergreen forest variables.  As indicated by the partial dependency plots (Figure \ref{fig:gis_partial_dependence}), chlorophyll *a* increases with cropland and decreases with evergreen cover.  It is not surprising that croplands were selected given the overwhelming impact of agriculture on the eutrophication process.   The negative association of evergreens and chlorophyll *a* concentrations (Figure \ref{fig:gis_partial_dependence}).  As the percent of evergreens increases we are likely to see increased elevation and soil differences that limit agriculture.  

Lastly, morphometry (e.g. depth) also proved to be important in the prediction of lake trophic state [@genkai2005eutrophication].  As morphometry shows little to no broad scale spatial pattern and is unique to a given lake, these data are likely illuminating the local, lake scale drivers such as in-lake nutrient processing and residence time.

#Conclusions

Our research goals were to explore the utility of a widely used data mining algorithm, random forests, in the modelling of chlorophyll *a* and lake trophic state. Further, we hoped to examine the utility of these models when built with only ubiquitous GIS data, which allows estimation of trophic state for all lakes in the United States.  The "All variables" model had an RMSE of `r round(all_rf$mse[all_rf$ntree],2)` and an adjusted R\textsuperscript{2} of `r round(all_rf$rsq[all_rf$ntree],2)` whereas, the GIS only models had an RMSE of `r round(gis_rf$mse[gis_rf$ntree],2)` and the adjusted R\textsuperscript{2} was `r round(gis_rf$rsq[gis_rf$ntree],2)`.  Our total accuracy in predicting chlorophyll *a* based trophic states was `r round(all_ts4_total_acc,2)*100`% for the "All variables" model and `r round(gis_ts4_total_acc,2)*100`% for the "GIS only" model.  

While the "GIS only" model showed lower prediction accuracies than the "All variables" model, the association between the uncertainty of prediction and total accuracy (Figure \ref{fig:condProbFig} and Table \ref{tab:cond_prob_tab}) suggest that the "GIS only" model will provide reasonable estimates of trophic state for many lakes across the United States.  Furthermore, we can map the uncertainty of the predictions, thus, we know the spatial patterns and location of the lakes for which we are certain, or not, of their predicted trophic state.  Given this and that these models may be applied to any lake in the United States we can recomend using this model.  Future iterations of this modelling effort may be able to utilize modeled predictions of nutrients to improve accuracy and also maintain broad applicability [@milstead2013estimating].

For the "All variables" model, the *in situ* water quality variables drove the predictions.  This is not surprising.  For the "GIS only"" model,  the results were more nuanced. Three broad categories were routinely being selected as important: broad scale spatial patterns in trophic state, land use/land cover controls of trophic state, and local, lake-scale control driven by lake morphometry.  

A potentially usfeful benefit of models of trophic state and chlorophyll *a* are their use in assesing risk due to cyanobacteria.  Cyanobacteria biomass should be closely associated with chlorophyll *a* and trophic state as cyanobacteria contribute to the chlorophyll concentration in a lake. If these associations are strong enough we may be able to expand models such as those reported here to also predict probability of cyanobacteria blooms and other indices realted to cyanobcteria (e.g. toxin presence).  Others have seen these associations.  For instance, Yuan et al. [-@yuan2014managing] used the 2007 NLA to demonstrate that total nitrogen and chlorophyll *a* concentrations were good predictors of World Health Organization microcystin (a toxin produced by some cyanobacteria) criteria exceedences.  Using this same data, we see a positive trend between cholorophyll *a* and cyanobacteria abundance (Figure \ref{fig:scatterplot}).  Both of these suggest that trophic state may be an acceptable proxy for cyanobacteria abundance or presence of microcystin.  

Our results raise three important considerations related to managing eutrophication.  First, the broad scale patterning, indicated by ecoregion as an important variable, suggests regional trends.  This is noteworthy because it suggests that efforts to monitor, model and manage eutrophication and cyanobacteria should be undertaken at both national and regional levels.  Second, while direct control of water quality in lakes would have a large impact, the land use/land cover drivers (i.e. non-point sources) of water quality are also important, and better management of the spatial distribution of important classes such as forest and agriculture can provide some level of control on trophic state and amount of cyanobacteria present.  Third, in-lake processes (i.e. residence time, nutrient cycling, etc.) are, as expected, important and need to be part of any management strategy.  Building on these efforts through updated models,  direct prediction of cyanobacteria, and additional information on the regional differences will help us get a better handle on the broad scale dynamics of productivity in lakes and the potential risk to human health from cyanobacteria blooms.

#Acknowledgements
We would like to thank Farnaz Nojavan, Nathan Schmucker, John Kiddon, Joe LiVolsi, Tim Gleason, and Wayne Munns for constructive reviews of this paper.  This paper has not been subjected to Agency review. Therefore, it does not necessary reflect the views of the Agency. Mention of trade names or commercial products does not constitute endorsement or recommendation for use. This contribution is identified by the tracking number ORD-011075 of the Atlantic Ecology Division, Office of Research and Development, National Health and Environmental Effects Research Laboratory, US Environmental Protection Agency.

\newpage

#Figures

```{r figSetup,echo=FALSE,eval=FALSE,cache=FALSE}
###REDO
#create list of all selected variables and assign a color
vars<-ls(pattern="_vars")
all_vars<-vector()
for(i in vars){
  all_vars<-c(all_vars,get(i))
}
all_vars<-unique(all_vars)

#all_movies_palette<-vector()
#for(i in 1:dim(namelist)[1]){
#  all_movies_palette<-c(all_movies_palette,wes.palette(namelist[i,2],
#                                                       namelist[i,1]))
#}
#all_movies_palette<-unique(all_movies_palette)
#zissou<-c(wes.palette(5,"Zissou"),wes.palette(5,"Rushmore"))
#col_lu<-data.frame(variables=all_vars,hexcode=sample(all_movies_palette,length(all_vars)))
```


```{r fig1_nlaMap,eval=TRUE, echo=FALSE, fig.cap="Map of the distribution of National Lakes Assesment Sampling locations \\label{fig:nlaMap}",cache=FALSE}
state<-map_data('state')
lakes_alb<-data.frame(ltmData[["AlbersX"]],ltmData[["AlbersY"]])
p4s<-"+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=37.5 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m +no_defs"
ll<-"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs"
lakes_alb_sp<-SpatialPoints(coordinates(lakes_alb),proj4string=CRS(p4s))
lakes_dd<-spTransform(lakes_alb_sp,CRS=CRS(ll))
lakes_dd<-data.frame(coordinates(lakes_dd))
#mycolor<-wes.palette(5,"Rushmore")
#mycolor<-c(mycolor[1],mycolor[2],mycolor[4])
mycolor<-c("grey25","white","black")
names(lakes_dd)<-c("long","lat",c())
nlaMap(state,lakes_dd,mycolor)
```

\newpage

```{r all_var_sel_figure, eval=TRUE,results="asis",echo=FALSE, fig.cap="Variable selection plot for all variables.  Shows percent increase in mean squared error as a function of the number of variables.  \\label{fig:all_varsel_figure}",cache=FALSE}
varsel_plot(all_vs)
```

\newpage

```{r All_Importance, eval=TRUE,results="asis",echo=FALSE, fig.cap="Importance plot for All Variables., shows percent increase in mean square error.  Higher values of percent increase in mean squared error indicates higher importance.  \\label{fig:All_Importance}",cache=FALSE}
importancePlot(all_rf, data_def=data_def,type='acc',size=5)#,aes(colour=all_ts4_color))
```

\newpage

```{r all_partial_dependence, eval=TRUE, echo=FALSE, fig.cap="All Variables partial dependence plots for the top 5 most important variables. \\label{fig:all_partial_dependence}",cache=FALSE, warning=FALSE,fig.height=7}
multiplot(plot_pd(all_rf_turb_pd),
          plot_pd(all_rf_ntl_pd),
          plot_pd(all_rf_ptl_pd),
          plot_pd(all_rf_elev_pd),
          plot_pd(all_rf_toc_pd),
          plot_pd(all_rf_np_pd),
          layout=matrix(1:6,ncol=2,byrow=TRUE))
```

\newpage

```{r gis_var_sel_figure, eval=TRUE,results="asis",echo=FALSE, fig.cap="Variable selection plot for GIS only variables. Shows percent increase in mean squared error as a function of the number of variables.  \\label{fig:gis_varsel_figure}",cache=FALSE}
varsel_plot(gis_vs)
```

\newpage

```{r GIS_Importance, eval=TRUE,results="asis",echo=FALSE, fig.cap="Importance plot for GIS Only Variables., shows percent increase in mean square error.  Higher values of percent increase in mean squared error indicates higher importance.  \\label{fig:GIS_Importance}",cache=FALSE}
importancePlot(gis_rf, data_def=data_def,type='acc',size=5)#,aes(colour=all_ts4_color))
```

\newpage

```{r gis_partial_dependence,eval=TRUE, echo=FALSE, fig.cap="GIS Only Variables partial dependence plots for the top 5 most important variables. \\label{fig:gis_partial_dependence}",cache=FALSE, warning=FALSE, message=FALSE,fig.height=7}

multiplot(plot_pd(gis_rf_ecor_pd),
          plot_pd(gis_rf_crops_pd),
          plot_pd(gis_rf_elev_pd),
          plot_pd(gis_rf_lat_pd),
          plot_pd(gis_rf_conifer_pd),
          plot_pd(gis_rf_mndepth_pd),
          layout=matrix(1:6,ncol=2,byrow=TRUE))
```

\newpage

```{r prob_cdf, eval=TRUE, results="asis",echo=FALSE, fig.cap="Prediction probabilities for the All Variables and GIS Only models.  \\label{fig:prob_cdf}",cache=FALSE}
prob_cdf(all_rf_ts_prob, gis_rf_ts_prob,x="Predicition Probability",y="Proportion of Samples")
```

\newpage

```{r cond_prob_fig,  eval=TRUE, results="asis",echo=FALSE, fig.cap="Accuracy of predictions as a function of lake prediction probability. The x-axis represents lakes with a prediction probability at a given level or higher.  \\label{fig:cond_prob_fig}",cache=FALSE}
#This also writes out cp1 and cp2 to global env.
condAccuracy(all_rf_ts_prob,gis_rf_ts_prob,xImpair=0,R=1,xlab="Xc >= Prediction Probability")
```

\newpage

```{r gis_probability_map, eval=TRUE, results="asis",echo=FALSE, fig.cap="Maps of prediction probabilities for each of the four chlorophyll \\textit{a} trophic states  \\label{fig:gis_probability_map}",cache=FALSE,fig.height=7}
state<-map_data('state')
lakes_alb<-data.frame(ltmData[["AlbersX"]],ltmData[["AlbersY"]],
                     ltmData[["NLA_ID"]])
p4s<-"+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=37.5 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m +no_defs" 
ll<-"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs" 
lakes_alb_sp<-SpatialPointsDataFrame(coordinates(lakes_alb[,1:2]),proj4string=CRS(p4s),
                                    data=data.frame(nla_id = as.character(lakes_alb[,3])))
lakes_dd<-spTransform(lakes_alb_sp,CRS=CRS(ll))
lakes_dd<-data.frame(coordinates(lakes_dd),lakes_dd$nla_id)
names(lakes_dd)<-c("long","lat","nla_id")
ts_prob_map(state,lakes_dd,gis_rf_ts_prob)
```

\newpage

```{r predicted_prob_map,eval=TRUE, results="asis",echo=FALSE, fig.cap="Maps of prediction probabilities for the discrete, predicted chlorophyll \\textit{a} trophic state.  Shows spatial patterns of prediction uncertainty.  \\label{fig:predicted_prob_map}",cache=FALSE,fig.height=7}

pred_prob_map(state,lakes_dd,gis_rf_ts_prob)
```

\newpage

```{r pred_prob_dist, eval=TRUE, results="asis",echo=FALSE, fig.cap="Distribution of predicted probabilities.  \\label{fig:predicted_prob_dist}",cache=FALSE,fig.height=7}
density_plot(gis_rf_ts_prob,xvar="max",x="Predicted Probability")
```

\newpage

```{r chla_cyano_scatterplot,eval=TRUE,echo=FALSE, fig.cap="Cholorphyll *a* and cyanobacteria abundance scatterplot\\label{fig:scatterplot}",cache=FALSE}
scp_df<-data.frame(chla=ltmData[["CHLA"]],abundp1=ltmData[["cyanoCellsPerML"]]+1)
scatterPlot(scp_df,xvar="chla",yvar="abundp1","black","grey50","grey25",
             x=expression(paste('Log10(Chl ', italic("a"),' (',mu,'g/L))')),
             y="Log10(Cyanobaterial Abundance (cells/ml) + 1)")
```

\newpage

#Tables

```{r trophicStateTable,eval=TRUE, results='asis', echo=FALSE, tab.cap="Chlorophyll a based trophic state cut-offs. \\label{tab:trophicStateTable}",cache=FALSE}
ts_4<-c("oligotrophic","mesotrophic","eutrophic","hypereutrophic")
ts_3<-c("oligotrophic","mesotrophic/eutrophic","mesotrophic/eutrophic","hypereutrophic")
ts_2<-c("oligotrophic/mesotrophic","oligotrophic/mesotrophic","eutrophic/hypereutrophic","eutrophic/hypereutrophic")
co<-c("<= 2",">2-7",">7-30",">30")
xdf<-data.frame(ts_4,ts_2,co)
names(xdf)<-c("Trophic State (4 class)","Trophic State (2 class)",
              "Concentration Cut-off")
kable(xdf)
```

\newpage

```{r Confusion_All_4,eval=TRUE,results="asis",echo=FALSE, tab.cap="Random Forest confusion matrix for All Variables model converted to 4 trophic states. Columns show predicted values and rows show observed values.  Agreement indicated on diagonal and accuracy for each trophic state indicated in 'Class Accuracy' column. \\label{tab:Confusion_All_4}",cache=FALSE}
#NEED TO FIX ALL OF THESE - Tables not DFs and need to get class accuracy added
cmt<-table_to_df(round(all_ts4_conmat,2)) 
cmt$Class_Accuracy <- apply(cmt,1,sum)
for(i in 1:nrow(cmt)){
  cmt$Class_Accuracy[i]<-round((cmt[i,i]/cmt$Class_Accuracy[i])*100,2)
}
dimnames(cmt)[[2]][5]<-'Class Accuracy (%)'
kable(cmt,row.names=T)
```

\newpage

```{r Confusion_GIS_4,eval=TRUE,results="asis",echo=FALSE, tab.cap="Random Forest confusion matrix for GIS Only model converted to 4 tropic states. Columns show predicted values and rows show observed values.  Agreement indicated on diagonal and accuracy for each trophic state indicated in 'Class Accuracy' column.  \\label{tab:Confusion_GIS_4}",cache=FALSE}
cmt<-table_to_df(round(gis_ts4_conmat,2)) 
cmt$Class_Accuracy <- apply(cmt,1,sum)
for(i in 1:nrow(cmt)){
  cmt$Class_Accuracy[i]<-round((cmt[i,i]/cmt$Class_Accuracy[i])*100,2)
}
dimnames(cmt)[[2]][5]<-'Class Accuracy (%)'
kable(cmt,row.names=T)
```

\newpage

```{r cond_prob_tab, eval=TRUE,results="asis",echo=FALSE, tab.cap="Summary of relationship between prediction probabilities, total accuracy, and number of lakes.  \\label{tab:cond_prob_tab}",cache=FALSE}
all_min<-cp1
all_50<-cp1[cp1[,1]>=0.5,]
all_60<-cp1[cp1[,1]>=0.6,]
all_70<-cp1[cp1[,1]>=0.7,]
all_80<-cp1[cp1[,1]>=0.8,]
all_90<-cp1[cp1[,1]>=0.9,]

gis_min<-cp2
gis_50<-cp2[cp2[,1]>=0.5,]
gis_60<-cp2[cp2[,1]>=0.6,]
gis_70<-cp2[cp2[,1]>=0.7,]
gis_80<-cp2[cp2[,1]>=0.8,]
gis_90<-cp2[cp2[,1]>=0.9,]

#####################################FIX ME#####################################
#Sample size numbers are off, becuase duplicates dropped by cprob.  
#Need to adjust these from the raw data.

condprob_t<-data.frame(pred_prob=c("All","0.50","0.60","0.70","0.80","0.90"),
                       all_acc = c(all_min[1,2],all_50[1,2],all_60[1,2],
                                   all_70[1,2],all_80[1,2],all_90[1,2]),
                       all_perc = c((nrow(all_min)/nrow(all_min)),
                                    (nrow(all_50)/nrow(all_min)),
                                    (nrow(all_60)/nrow(all_min)),
                                    (nrow(all_70)/nrow(all_min)),
                                    (nrow(all_80)/nrow(all_min)),
                                    (nrow(all_90)/nrow(all_min))),
                       all_samp = c(nrow(all_min),nrow(all_50),nrow(all_60),
                                    nrow(all_70),nrow(all_80),nrow(all_90)),
                       gis_acc = c(gis_min[1,2],gis_50[1,2],gis_60[1,2],
                                   gis_70[1,2],gis_80[1,2],gis_90[1,2]),
                       gis_perc= c((nrow(gis_min)/nrow(gis_min)),
                                    (nrow(gis_50)/nrow(gis_min)),
                                    (nrow(gis_60)/nrow(gis_min)),
                                    (nrow(gis_70)/nrow(gis_min)),
                                    (nrow(gis_80)/nrow(gis_min)),
                                    (nrow(gis_90)/nrow(gis_min))),
                       gis_samp=c(nrow(gis_min),nrow(gis_50),nrow(gis_60),
                                    nrow(gis_70),nrow(gis_80),nrow(gis_90)))
condprob_t[,2:7]<-round(condprob_t[,2:7],2)
condprob_t[,2:3]<-100*condprob_t[,2:3]
condprob_t[,5:6]<-100*condprob_t[,5:6]
names(condprob_t)<-c("Prediction\nProb.",
                     "\"All Var.\"\nTotal Accuracy",
                     "\"All Var.\"\nPercent of Sample",
                     "\"All Var.\"\nNumber of Samples",
                     "\"GIS Only\"\nTotal Accuracy",
                     "\"GIS Only\"\nPercent of Sample",
                     "\"GIS Only\"\nNumber of Samples")
#kable(condprob_t,row.names=F)
pander::pandoc.table(condprob_t,keep.line.breaks=T,split.tables=Inf)
```

\newpage

#Appendix 1. Variable Definitions

```{r data_def,eval=TRUE, results="asis",echo=FALSE,cache=FALSE}
data_def<-arrange(data_def,type, variable_names)
names(data_def)<-c("Variable Names","Description", "Source")
kable(data_def,row.names=FALSE)
```

\newpage

#References
